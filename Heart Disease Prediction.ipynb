# HEART DISEASE PREDICTION SYSTEM
# Name - Sundaram Saurabh
# University Roll Number :- 2013539

# Important Libraries

#Importing Libraries
import numpy as np  #to work with arrays
import pandas as pd #to work with dataset
import matplotlib.pyplot as plt #to create charts using pyplot
from matplotlib import rcParams #to define parameters using rcParams
from matplotlib.cm import rainbow #to color them with cm.rainbow
%matplotlib 
import warnings #to ignore all warnings which might be showing up
warnings.filterwarnings('ignore')

# Libraries for processing the data

from sklearn.model_selection import train_test_split  #to split the dataset into training and testing data
from sklearn.preprocessing import StandardScaler  #To scale all the features, so that the machine learning model better adapts to the dataset

# Library for machine learning algorithm

from sklearn.neighbors import KNeighborsClassifier

# Uploading the dataset

dataset = pd.read_csv('heart.csv')

# Basic information about dataset

dataset.info()  #to see basic information of dataset

dataset.describe()  #to see the mean,meadian,standard deviation etc.

# Data Visualization

import seaborn as sns
#get correlations of each features in dataset
corrmat = dataset.corr()
top_corr_features = corrmat.index
plt.figure(figsize=(20,20))
#plot heat map
g=sns.heatmap(dataset[top_corr_features].corr(),annot=True,cmap="RdYlGn")

![image.png](attachment:image.png)

dataset.hist()  #to see histograms for each variables

![image.png](attachment:image.png)

#to check whether the target classes are of approximately equal size or not
rcParams['figure.figsize'] = 8,6
plt.bar(dataset['target'].unique(), dataset['target'].value_counts(), color = ['red', 'green'])
plt.xticks([0, 1])
plt.xlabel('Target Classes')
plt.ylabel('Count')
plt.title('Count of each Target Class')

![image.png](attachment:image.png)

# Data Processing

#get_dummies method to create dummy columns for categorical variables.
dataset = pd.get_dummies(dataset, columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal'])

#use of StandardScaler from sklearn to scale the dataset
standardScaler = StandardScaler()
columns_to_scale = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']
dataset[columns_to_scale] = standardScaler.fit_transform(dataset[columns_to_scale])

dataset.head()

# Splitting the dataset

y = dataset['target']
X = dataset.drop(['target'], axis = 1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)

# KNN Classifier

knn_scores = []
for k in range(1,21):
    knn_classifier = KNeighborsClassifier(n_neighbors = k)
    knn_classifier.fit(X_train, y_train)
    knn_scores.append(knn_classifier.score(X_test, y_test))

plt.plot([k for k in range(1, 21)], knn_scores, color = 'red')
for i in range(1,21):
    plt.text(i, knn_scores[i-1], (i, knn_scores[i-1]))
plt.xticks([i for i in range(1, 21)])
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Scores')
plt.title('K Neighbors Classifier scores for different K values')

![image.png](attachment:image.png)

From the plot above, it is clear that the maximum score achieved was 0.87 for the 8 neighbors.

print("The score for K Neighbors Classifier is {}% with {} nieghbors.".format(knn_scores[7]*100, 8))
